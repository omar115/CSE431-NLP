{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentence_polarity.zip', 'mac_morpho', 'abc.zip', 'webtext.zip', 'lin_thesaurus.zip', 'biocreative_ppi', 'cess_esp.zip', 'verbnet', 'verbnet.zip', 'unicode_samples.zip', 'crubadan', 'crubadan.zip', 'framenet_v17', 'udhr2.zip', 'brown_tei.zip', 'comparative_sentences.zip', 'brown.zip', 'city_database', 'alpino', 'treebank', 'conll2000.zip', 'universal_treebanks_v20.zip', 'ieer.zip', 'mte_teip5.zip', 'comparative_sentences', 'movie_reviews.zip', 'nps_chat.zip', 'chat80.zip', 'nps_chat', 'senseval.zip', 'europarl_raw', 'conll2002.zip', 'dolch', 'rte.zip', 'udhr2', 'pil', 'framenet_v17.zip', 'pros_cons.zip', 'dependency_treebank', 'pros_cons', 'comtrans.zip', 'cess_cat', 'genesis', 'gazetteers.zip', 'dependency_treebank.zip', 'stopwords.zip', 'biocreative_ppi.zip', 'brown', 'indian.zip', 'product_reviews_1', 'paradigms', 'cess_esp', 'paradigms.zip', 'ycoe', 'kimmo', 'switchboard', 'omw', 'product_reviews_2', 'nombank.1.0.zip', 'twitter_samples', 'conll2007.zip', 'sentiwordnet.zip', 'masc_tagged.zip', 'wordnet', 'sentiwordnet', 'wordnet_ic.zip', 'cmudict.zip', 'product_reviews_2.zip', 'inaugural', 'mac_morpho.zip', 'words', 'subjectivity', 'chat80', 'alpino.zip', 'opinion_lexicon.zip', 'floresta', 'words.zip', 'ppattach', 'propbank.zip', 'timit', 'panlex_swadesh.zip', 'pl196x', 'toolbox', 'ieer', 'wordnet.zip', 'cess_cat.zip', 'problem_reports', 'dolch.zip', 'swadesh', 'reuters.zip', 'toolbox.zip', 'stopwords', 'abc', 'genesis.zip', 'wordnet_ic', 'names', 'inaugural.zip', 'nonbreaking_prefixes.zip', 'gazetteers', 'smultron.zip', 'kimmo.zip', 'problem_reports.zip', 'verbnet3.zip', 'ptb', 'state_union.zip', 'shakespeare', 'framenet_v15.zip', 'switchboard.zip', 'gutenberg.zip', 'shakespeare.zip', 'qc', 'pl196x.zip', 'jeita.zip', 'unicode_samples', 'conll2002', 'europarl_raw.zip', 'cmudict', 'nonbreaking_prefixes', 'conll2000', 'ppattach.zip', 'machado.zip', 'gutenberg', 'swadesh.zip', 'indian', 'ptb.zip', 'udhr.zip', 'qc.zip', 'rte', 'mte_teip5', 'product_reviews_1.zip', 'sinica_treebank', 'sinica_treebank.zip', 'knbc.zip', 'opinion_lexicon', 'ycoe.zip', 'verbnet3', 'city_database.zip', 'names.zip', 'treebank.zip', 'twitter_samples.zip', 'subjectivity.zip', 'framenet_v15', 'smultron', 'sentence_polarity', 'floresta.zip', 'udhr', 'semcor.zip', 'omw.zip', 'state_union', 'senseval', 'movie_reviews', 'timit.zip', 'lin_thesaurus', 'pil.zip', 'webtext', 'brown_tei']\n"
     ]
    }
   ],
   "source": [
    "#go through the corpura of nltk collection\n",
    "#some have textual data and some have functional data and so on..\n",
    "print(os.listdir(nltk.data.find(\"corpora\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exploring brown data\n",
    "from nltk.corpus import brown\n",
    "brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#explore text files\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore hamlet\n",
    "hamlet=nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TheTragedieofHamletbyWilliamShakespeare1599]ActusPrimus.ScoenaPrima.EnterBarnardoandFranciscotwoCentinels.Barnardo.Who'sthere?Fran.Nayanswerme:Stand&vnfoldyourselfeBar.LongliuetheKingFran.Barnardo?Bar.HeFran.YoucomemostcarefullyvponyourhoureBar.'Tisnowstrooktwelue,gettheetobedFranciscoFran.Forthisreleefemuchthankes:'Tisbittercold,AndIamsickeatheartBarn.Haueyouhad"
     ]
    }
   ],
   "source": [
    "#first 100 words of hamlet\n",
    "for word in hamlet[:100]:\n",
    "    print(word, sep='',end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create my dataset\n",
    "irl = \"\"\"In the early 2000s, this meant focusing on problems like flying helicopters and walking up \n",
    "flights of stairs.\n",
    "However, there’s still a massive list of problems where humans outperform machines. \n",
    "Although we can no longer claim to beat machines at tasks like Go and image classification,\n",
    "we have a distinct advantage in solving problems that aren’t as well-defined,\n",
    "like judging a well-executed backflip, cleaning a room while preventing accidents, \n",
    "and perhaps the most human problem of all: reasoning about people’s values. \n",
    "Since all these tasks contain some degree of subjectivity, \n",
    "machines need information about the world as well as a way to learn about the people \n",
    "within it in order to solve these problems.\n",
    "\n",
    "The two tasks of inverse reinforcement learning and apprenticeship learning, \n",
    "formulated almost two decades ago, are closely related to these discrepancies. \n",
    "And solutions to these tasks can be an important step towards our larger goal of learning from humans.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(irl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'the',\n",
       " 'early',\n",
       " '2000s',\n",
       " ',',\n",
       " 'this',\n",
       " 'meant',\n",
       " 'focusing',\n",
       " 'on',\n",
       " 'problems',\n",
       " 'like',\n",
       " 'flying',\n",
       " 'helicopters',\n",
       " 'and',\n",
       " 'walking',\n",
       " 'up',\n",
       " 'flights',\n",
       " 'of',\n",
       " 'stairs',\n",
       " '.',\n",
       " 'However',\n",
       " ',',\n",
       " 'there',\n",
       " '’',\n",
       " 's',\n",
       " 'still',\n",
       " 'a',\n",
       " 'massive',\n",
       " 'list',\n",
       " 'of',\n",
       " 'problems',\n",
       " 'where',\n",
       " 'humans',\n",
       " 'outperform',\n",
       " 'machines',\n",
       " '.',\n",
       " 'Although',\n",
       " 'we',\n",
       " 'can',\n",
       " 'no',\n",
       " 'longer',\n",
       " 'claim',\n",
       " 'to',\n",
       " 'beat',\n",
       " 'machines',\n",
       " 'at',\n",
       " 'tasks',\n",
       " 'like',\n",
       " 'Go',\n",
       " 'and',\n",
       " 'image',\n",
       " 'classification',\n",
       " ',',\n",
       " 'we',\n",
       " 'have',\n",
       " 'a',\n",
       " 'distinct',\n",
       " 'advantage',\n",
       " 'in',\n",
       " 'solving',\n",
       " 'problems',\n",
       " 'that',\n",
       " 'aren',\n",
       " '’',\n",
       " 't',\n",
       " 'as',\n",
       " 'well-defined',\n",
       " ',',\n",
       " 'like',\n",
       " 'judging',\n",
       " 'a',\n",
       " 'well-executed',\n",
       " 'backflip',\n",
       " ',',\n",
       " 'cleaning',\n",
       " 'a',\n",
       " 'room',\n",
       " 'while',\n",
       " 'preventing',\n",
       " 'accidents',\n",
       " ',',\n",
       " 'and',\n",
       " 'perhaps',\n",
       " 'the',\n",
       " 'most',\n",
       " 'human',\n",
       " 'problem',\n",
       " 'of',\n",
       " 'all',\n",
       " ':',\n",
       " 'reasoning',\n",
       " 'about',\n",
       " 'people',\n",
       " '’',\n",
       " 's',\n",
       " 'values',\n",
       " '.',\n",
       " 'Since',\n",
       " 'all',\n",
       " 'these',\n",
       " 'tasks',\n",
       " 'contain',\n",
       " 'some',\n",
       " 'degree',\n",
       " 'of',\n",
       " 'subjectivity',\n",
       " ',',\n",
       " 'machines',\n",
       " 'need',\n",
       " 'information',\n",
       " 'about',\n",
       " 'the',\n",
       " 'world',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'a',\n",
       " 'way',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'about',\n",
       " 'the',\n",
       " 'people',\n",
       " 'within',\n",
       " 'it',\n",
       " 'in',\n",
       " 'order',\n",
       " 'to',\n",
       " 'solve',\n",
       " 'these',\n",
       " 'problems',\n",
       " '.',\n",
       " 'The',\n",
       " 'two',\n",
       " 'tasks',\n",
       " 'of',\n",
       " 'inverse',\n",
       " 'reinforcement',\n",
       " 'learning',\n",
       " 'and',\n",
       " 'apprenticeship',\n",
       " 'learning',\n",
       " ',',\n",
       " 'formulated',\n",
       " 'almost',\n",
       " 'two',\n",
       " 'decades',\n",
       " 'ago',\n",
       " ',',\n",
       " 'are',\n",
       " 'closely',\n",
       " 'related',\n",
       " 'to',\n",
       " 'these',\n",
       " 'discrepancies',\n",
       " '.',\n",
       " 'And',\n",
       " 'solutions',\n",
       " 'to',\n",
       " 'these',\n",
       " 'tasks',\n",
       " 'can',\n",
       " 'be',\n",
       " 'an',\n",
       " 'important',\n",
       " 'step',\n",
       " 'towards',\n",
       " 'our',\n",
       " 'larger',\n",
       " 'goal',\n",
       " 'of',\n",
       " 'learning',\n",
       " 'from',\n",
       " 'humans',\n",
       " '.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(irl)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no of tokens\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting frequency\n",
    "#I want to count words and put\n",
    "# a frequency of these words\n",
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 9, 'of': 6, '.': 6, 'the': 5, 'and': 5, 'a': 5, 'to': 5, 'problems': 4, 'tasks': 4, 'these': 4, ...})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similar in book i want to see\n",
    "#the frequency of a word in my dataset\n",
    "for word in tokens:\n",
    "    fdist[word.lower()] += 1\n",
    "fdist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
